%!TEX root = ../thesis.tex

% ~2 pages

\chapter[research hypotheses and contributions]{Research hypotheses and contributions}\label{chp:main-contributions}

\newcommand{\contribitem}[1]{{\vspace{1em}\noindent\scshape\bfseries\Large{\color{dtured}\cref{#1}}\\\ucnameref{#1}}\\}

The following chapters of the thesis are self-contained studies and therefore detail their own research hypotheses and contributions.
Since each study was written without consideration to the other chapters of the thesis, we here detail them in relation to the overall research project. 
This constitutes the research hypotheses and contributions of the thesis.

% The chapters are structured into three parts: {\color{black}\cref{part:unsupervised-uncertainty-estimation}} is concerned with unsupervised uncertainty estimation, {\color{black}\cref{part:unsupervised-speech-representation-learning}} is concerned with self"=supervised speech representation learning, and {\color{black}\cref{part:medical-applications}} contains studies on machine learning methods applied for tasks in a medical setting.  Finally, {\color{black}\cref{part:discussion-and-conclusion}} contains a discussion and the conclusion of the thesis.


\contribitem{part:background}
\Cref{chp:introduction} provides a general introduction to the thesis and gives motivating examples for speech recognition and assistance in medical encounters including stroke recognition on medical helplines and automation of medical coding. \Cref{chp:technical-background} provides additional technical background not included in the individual studies. It introduces uncertainty as a concept in the context of information and probability theory, introduces the task of out-of-distribution detection and provides a review of existing work on the problem, and lays out the foundations for variational autoencoders. 


\contribitem{part:unsupervised-uncertainty-estimation}
This part of the thesis is concerned with unsupervised uncertainty estimation and consists of three papers. 
The first two papers approach unsupervised uncertainty estimation through the task of out-of-distribution detection using generative models. 
The first paper proposes a new method for out-of-distribution detection using hierarchical variational autoencoders and the second proposes a model-agnostic method for that can be used with any differentiable generative model with explicit likelihood. 
The third paper proposes a new hierarchical variational autoencoder for speech and benchmarks it against other variational and autoregressive models.

\contribitem{chp:paper-hierarchical}
In this work we hypothesize that the likelihood estimate of variational autoencoders is a poor score for out-of-distribution due to an overemphasis on low-level features that generalize between distributions. 
We further hypothesize that a well-formed hierarchy of latent variables provides a tool that can be used to select which features to emphasize for out-of-distribution detection and hence a way to improve the performance of variational autoencoders on this task. 
We proceed to provide empirical and theoretical evidence that low-level features indeed do dominate the likelihood and propose a new method for out-of-distribution detection using hierarchical variational autoencoders. 
The proposed method computes a likelihood-ratio score for out-of-distribution detection that requires data to be in-distribution across all feature-levels. 
The proposed method is computationally efficient, fully unsupervised, and performs well on several out-of-distribution detection benchmarks. 
% Methods like this are important for the development of safe and reliable machine learning systems, especially in medical applications where the consequences of errors can be significant. 

\contribitem{chp:paper-modelagnostic}
In this follow-up work, we note that many methods have been proposed for out-of-distribution detection using generative models, with some tailored for specific model types, and seek to develop a model-agnostic approach. 
We hypothesize that by phrasing the problem as a statistical testing problem and combining different tests, the method's efficacy can be improved and weaknesses inherent to any particular test alleviated. 
From this hypothesis, we develop a method that combines a classical parametric test with the recently introduced typicality test and can be used with any differentiable, explicit likelihood generative model.
We show that this leads to a more accurate out-of-distribution test. 
Finally, we discuss the benefits of casting out-of-distribution detection as a statistical testing problem, for instance enabling false positive rate control. This is valuable for practical applications, especially in high-risk settings such as medical decision-making.

\moretodo[inline]{Revise the location of the benchmarking paper and change the SSL review to the SSL+LVM brief review. Revise the text here accordingly. $\downarrow$}

\contribitem{chp:paper-benchmarking}
In this paper, we focus on benchmarking hierarchical variational autoencoders for speech modelling. 
We hypothesize that the improvements in likelihood scores proven by hierarchical models in other domains, most prominently images, can also carry over to speech modelling. 
To this end, we benchmark a number of existing deterministic and stochastic models and adapt the hierarchical Clockwork VAE developed for video \parencite{saxena_clockwork_2021} to speech data. 
We show that using a hierarchy of latent variables can improve the likelihood of the model and that the learned latent space captures information relevant for speech recognition, such as phonetic content. 
% This paper proposes a new hierarchical variational autoencoder for speech inspired by the Clockwork VAE \parencite{saxena_clockwork_2021}. 
% The model is benchmarked against other variational autoencoders and autoregressive models for speech. 


\contribitem{part:unsupervised-speech-representation-learning}
This part of the thesis is concerned with self"=supervised speech representation learning and consists of a single paper that provides a substantial review of the field \parencite{mohamed_selfsupervised_2022}. 
Self"=supervised learning is a promising approach to speech representation learning that has shown a fast, wide and successful adoption across speech modelling over the course of the last few years. 
As measured by performance on common downstream tasks such as speech recognition and spoken language understanding, self"=supervised representations generally outperform representations learned via probabilistic generative models such as those investigated in \cref{part:unsupervised-uncertainty-estimation}. 
In this review paper, we do not consider uncertainty estimation, but in future work, consideration should be given to the use of self"=supervised learning for learning representations for unsupervised uncertainty estimation. 
We shall return to this in the discussion of \cref{app:paper-review} in \cref{sec:discussion-paper-review}.
\moretodo[inline]{Edit this if we did not discuss this.}
An early version of this review paper included a review of variational autoencoders for speech representation learning and a comparison between the two modelling paradigms \parencite{borgholt_brief_2022}. 
Due to a desire to focus on self"=supervised methods, the paper in \cref{app:paper-review} does not put particular focus on variational methods. 
The early version is included in \cref{chp:paper-brief} for reference.

\contribitem{app:paper-review}
This paper provides a comprehensive review of self"=supervised speech representation learning. Previous work is grouped into three main categories of methods: contrastive, autoregressive, and generative, and the methods are compared in terms of their training objectives, model architectures, and performance on downstream tasks. The review also provides a discussion of the current state of the field and promising future directions of research. 

\moretodo[inline]{Revise the location of the benchmarking paper and change the SSL review to the SSL+LVM brief review. Revise the text here accordingly. $\uparrow$}


 
\contribitem{part:medical-applications}
This part contains studies on machine learning methods applied for tasks in a medical setting. While uncertainty estimation is not a central theme to the two papers, the first paper performs a substantial evaluation of the explainability of the proposed model via an occlusion analysis on the text input. Later, in the discussion, we shall further consider uncertainty estimation in relation to these two papers.
\todo[inline]{Revise and add more details to this section. Do we discuss uncertainty for medical coding?}

\contribitem{chp:paper-automated}
In this paper, we review the current state-of-the-art in automated medical coding of clinical notes. 
We hypothesize that several previous works underperform for reasons more related to suboptimal hyperparameter tuning, incorrect evaluation, and crude data handling than to model design, and that performance and comparability can be improved by addressing these issues. 
With our work, we aim to improve reproducibility of future work and to provide a baseline for future comparisons. 
We first reproduce, analyze and compare several models on the MIMIC-III dataset showing that poor performance is indeed attributable to weak configuration of the training and crudely sampled train-test splits with many extremely rare classes and several without examples in the training data at all. 
We also identify and correct a widespread error in the calculation of the macro F1-score. 
To compare models, we propose new data splits created with stratified sampling, use identical experimental setups and tune hyperparameters and decision boundaries. 
By analyzing prediction errors, we confirm the observation of previous work that all models struggle with rare codes, although long documents only have a negligible impact on performance, contrary to previous claims. 
We also present the first comprehensive results on the newly released MIMIC-IV dataset using the reproduced models. 

\contribitem{chp:paper-retrospective}
In this paper we examine the hypothesis that a machine learning framework can learn to recognize cases of stroke in calls made to a prehospital medical helpline. 
We used calls from Copenhagen during 2015 to 2020, to develop a machine learning-based classification pipeline. First, calls were transcribed by a speech recognition model and then categorized as stroke or non-stroke using a text classification model.
On test data from 2021, call-takers achieved an overall sensitivity of 52.7\% (95\% confidence interval 49.2-56.4\%) with a positive predictive value (PPV) of 17.1\% (15.5-18.6\%) while the machine learning framework performed significantly better (p < 0.0001) with a sensitivity of 63.0\% (62.0-64.1\%) and a PPV of 24.9\% (24.3-25.5\%).
Effective treatment of out-of-hospital stroke often hinges on recognition by call-takers at prehospital telehealth services. 
This study provides preliminary evidence that a machine learning framework could become a supportive tool for call-takers at prehospital medical helplines, aiding in early and accurate stroke recognition.
% This paper aimed to develop and assess the potential of machine learning in improving prehospital stroke recognition during medical helpline calls. 
