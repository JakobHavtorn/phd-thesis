%!TEX root = ../thesis.tex

% ~2 pages

\chapter[research hypotheses and contributions]{Research hypotheses and contributions}\label{chp:main-contributions}

\newcommand{\contribitem}[1]{{\vspace{1em}\noindent\scshape\bfseries\Large{\color{dtured}\cref{#1}}\\\ucnameref{#1}}\\}

The chapters of \cref{part:unsupervised-uncertainty-estimation,part:unsupervised-speech-representation-learning,part:medical-applications} are self-contained studies and therefore detail their own research hypotheses and contributions.
Since each study was written without consideration to the other chapters of the thesis, we here detail them in relation to the overall research project. 
This constitutes the research hypotheses and contributions of the thesis.

% The chapters are structured into three parts: {\color{black}\cref{part:unsupervised-uncertainty-estimation}} is concerned with unsupervised uncertainty estimation, {\color{black}\cref{part:unsupervised-speech-representation-learning}} is concerned with self"=supervised speech representation learning, and {\color{black}\cref{part:medical-applications}} contains studies on machine learning methods applied for tasks in a medical setting.  Finally, {\color{black}\cref{part:discussion-and-conclusion}} contains a discussion and the conclusion of the thesis.


\contribitem{part:background}
\Cref{chp:introduction} provides a general introduction to the thesis and gives motivating examples for speech recognition and assistance in medical encounters including stroke recognition on medical helplines and automation of medical coding. \Cref{chp:technical-background} provides additional technical background not included in the individual studies. It introduces uncertainty as a concept in the context of information and probability theory and introduces the task of out-of-distribution detection and provides a review of existing work on the problem. Finally, it lays out the foundations for variational autoencoders. 


\contribitem{part:unsupervised-uncertainty-estimation}
This part of the thesis is concerned with unsupervised uncertainty estimation and consists of two papers. 
% The first two papers approach unsupervised uncertainty estimation through the task of out-of-distribution detection using generative models. 
Both papers focus on using generative models for out-of-distribution detection, which is the task of detecting data that are likely to be sampled from a different data generating distribution than the training data.
In both cases, the contributions are methodological and relate to developing improved methods for out-of-distribution detection.
% The first paper proposes a new method using hierarchical variational autoencoders while the second develops a model-agnostic, combined statistical test. 

\contribitem{chp:paper-hierarchical}
In this work we hypothesize that the likelihood estimate of variational autoencoders is a poor score for out-of-distribution due to an overemphasis on low-level features that generalize between distributions. 
We further hypothesize that a well-formed hierarchy of latent variables provides a tool that can be used to select which features to emphasize for out-of-distribution detection and, hence, a way to improve the performance of variational autoencoders on this task. 
We proceed to provide empirical and theoretical evidence that low-level features do indeed dominate the likelihood score and propose a new method for out-of-distribution detection using hierarchical variational autoencoders based on a likelihood-ratio score that requires data to be in-distribution across all feature-levels. 
The proposed method is computationally efficient, fully unsupervised, and performs well on several out-of-distribution detection benchmarks. 
% Methods like this are important for the development of safe and reliable machine learning systems, especially in medical applications where the consequences of errors can be significant. 

\contribitem{chp:paper-modelagnostic}
In this follow-up work to \cref{chp:paper-hierarchical}, we note that the set of methods proposed for out-of-distribution detection using generative models is quite large and that many are tailored for specific model types, which suggests that it is possible to develop a model-agnostic approach. We hypothesize that by phrasing the task as a statistical testing problem and combining different tests, the method's efficacy can be improved and weaknesses inherent to any particular test can be alleviated. 
From this hypothesis, we combine a classical parametric test with the recently introduced typicality test to develop a method applicable to any differentiable  generative model with explicit likelihood, and show that this leads to a more accurate out-of-distribution test. 
Finally, we discuss the benefits of casting out-of-distribution detection as a statistical testing problem, for instance enabling false positive rate control. This property is valuable in many practical applications, especially in high-risk settings such as medical decision-making.

% \moretodo[inline]{Revise the location of the benchmarking paper and change the SSL review to the SSL+LVM brief review. Revise the text here accordingly. $\downarrow$}

\contribitem{part:unsupervised-speech-representation-learning}
This part deals with unsupervised learning of speech representations and consists of two papers. Speech representations are fundamental to any practical system for decision-support as well as for uncertainty quantification on speech data. 
The contributions of this part lie in analyzing and comparing different approaches to speech representation along with a comprehensive overview of the field.

\contribitem{chp:paper-brief}
In this chapter, we present a comprehensive overview of unsupervised neural representation learning for speech. Previous research is categorized into self"-supervised methods and probabilistic latent variable models and described in a common notation. This description assists in developing a model taxonomy that shapes a discussion of the models' representational power, the associated learning strategies, and the methods used to evaluate them. The discussion points to interesting avenues of future research. 
An extended version of this overview paper that focuses exclusively on self"=supervised methods was also published as part of the project \ref{enumerate: paper-review} \parencite{mohamed_selfsupervised_2022}. This paper is included in \cref{app:paper-review} for reference.

\contribitem{chp:paper-benchmarking}
This chapter develops a novel hierarchical latent variable model for speech, drawing inspiration from the Clockwork VAE \parencite{saxena_clockwork_2021}. A comparative benchmark against alternative latent variable models and autoregressive models for speech highlights the improvements to likelihood brought by using hierarchical latent variables. The paper also analyzes the latent spaces learned by the models in terms of phonetic content.


% \contribitem{chp:paper-benchmarking}
% In this paper, we focus on benchmarking hierarchical variational autoencoders for speech modelling. 
% We hypothesize that the improvements in likelihood scores proven by hierarchical models in other domains, most prominently images, can also carry over to speech modelling. 
% To this end, we benchmark a number of existing deterministic and stochastic models and adapt the hierarchical Clockwork VAE developed for video \parencite{saxena_clockwork_2021} to speech data. 
% We show that using a hierarchy of latent variables can improve the likelihood of the model and that the learned latent space captures information relevant for speech recognition, such as phonetic content. 
% This paper proposes a new hierarchical variational autoencoder for speech inspired by the Clockwork VAE \parencite{saxena_clockwork_2021}. 
% The model is benchmarked against other variational autoencoders and autoregressive models for speech. 


% \contribitem{part:unsupervised-speech-representation-learning}
% This part of the thesis is concerned with self"=supervised speech representation learning and consists of a single paper that provides a substantial review of the field \parencite{mohamed_selfsupervised_2022}. 
% Self"=supervised learning is a promising approach to speech representation learning that has shown a fast, wide and successful adoption across speech modelling over the course of the last few years. 
% As measured by performance on common downstream tasks such as speech recognition and spoken language understanding, self"=supervised representations generally outperform representations learned via probabilistic generative models such as those investigated in \cref{part:unsupervised-uncertainty-estimation}. 
% In this review paper, we do not consider uncertainty estimation, but in future work, consideration should be given to the use of self"=supervised learning for learning representations for unsupervised uncertainty estimation. 
% We shall return to this in the discussion of \cref{app:paper-review} in \cref{sec:discussion-paper-review}.
% \moretodo[inline]{Edit this if we did not discuss this.}
% An early version of this review paper included a review of variational autoencoders for speech representation learning and a comparison between the two modelling paradigms \parencite{borgholt_brief_2022}. 
% Due to a desire to focus on self"=supervised methods, the paper in \cref{app:paper-review} does not put particular focus on variational methods. 
% The early version is included in \cref{chp:paper-brief} for reference.

% \contribitem{app:paper-review}
% This paper provides a comprehensive review of self"=supervised speech representation learning. Previous work is grouped into three main categories of methods: contrastive, autoregressive, and generative, and the methods are compared in terms of their training objectives, model architectures, and performance on downstream tasks. The review also provides a discussion of the current state of the field and promising future directions of research. 

% \moretodo[inline]{Revise the location of the benchmarking paper and change the SSL review to the SSL+LVM brief review. Revise the text here accordingly. $\uparrow$}

 
\contribitem{part:medical-applications}
This part contains two studies on machine learning methods applied for tasks in a medical setting. The contributions of the first are methodological focusing on improved comparability and reproducibility of studies on automated medical coding. The second is a retrospective study on machine learning-assisted stroke recognition focusing on the potential clinical impact of using machine learning to recognize stroke cases in emergency calls. 
While uncertainty estimation is not a central theme to the two papers, the retrospective study performs a substantial evaluation of the explainability of the proposed model via an occlusion analysis on the text input. 
Later, in the discussion, we shall further consider uncertainty estimation in relation to medical applications focusing on the retrospective study.
% \moretodo[inline]{Revise and add more details to this section. Do we discuss uncertainty for medical coding?}

\contribitem{chp:paper-automated}
In this paper, we review the current state-of-the-art in automated medical coding of clinical notes. 
We hypothesize that several previous works underperform for reasons more related to suboptimal hyperparameter tuning, incorrect evaluation, and crude data handling than to model design, and that performance and comparability can be improved by addressing these issues. 
We first reproduce, analyze and compare several models on the MIMIC-III dataset showing that poor performance is indeed attributable to weak configuration of the training and crudely sampled train-test splits with many extremely rare classes - several without examples in the training data. 
We also identify and correct a widespread error in the calculation of the macro F1-score. 
To compare models, we propose new data splits created with stratified sampling, use identical experimental setups and tune hyperparameters and decision boundaries. 
By analyzing prediction errors, we confirm the observation of previous work that all models struggle with rare codes, although, contrary to previous claims, long documents only have a negligible impact on performance. 
Finally, we present the first comprehensive results on the recently released MIMIC-IV dataset using the reproduced models. 

\contribitem{chp:paper-retrospective}
In this paper we examine the hypothesis that a machine learning framework can learn to recognize cases of stroke in calls made to a prehospital medical helpline. 
We used calls from Copenhagen during 2015 to 2020, to develop a machine learning-based classification pipeline. First, calls were transcribed by a speech recognition model and then categorized as stroke or non-stroke using a text classification model.
On test data from 2021, call-takers achieved an overall sensitivity of 52.7\% (95\% confidence interval 49.2-56.4\%) with a positive predictive value (PPV) of 17.1\% (15.5-18.6\%) while the machine learning framework performed significantly better (p < 0.0001) with a sensitivity of 63.0\% (62.0-64.1\%) and a PPV of 24.9\% (24.3-25.5\%).
Effective treatment of out-of-hospital stroke often hinges on recognition by call-takers at prehospital telehealth services. 
This study provides preliminary evidence that a machine learning framework could become a supportive tool for call-takers at prehospital medical helplines, aiding in early and accurate stroke recognition.
% This paper aimed to develop and assess the potential of machine learning in improving prehospital stroke recognition during medical helpline calls. 
