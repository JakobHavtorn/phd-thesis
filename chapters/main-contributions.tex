%!TEX root = ../thesis.tex

% ~2 pages

\chapter[main contributions]{Main contributions}\label{chp:main-contributions}
\newcommand{\contribitem}[1]{{\vspace{1em}\noindent\scshape\bfseries{\color{dtured}\cref{#1}}\\\ucnameref{#1}\\}}

The following chapters of the thesis are self-contained studies and therefore detail their own contributions. 
They are however written without consideration to the other chapters. 
For that reason, this chapter will describe the main contributions of each chapter in relation to the overall research topic of the thesis. 
The chapters are structured into three parts: \cref{part:unsupervised-uncertainty-estimation} is concerned with unsupervised uncertainty estimation, \cref{part:self-supervised-speech-representation-learning} is concerned with self-supervised speech representation learning, and \cref{part:medical-applications} contains studies on machine learning methods applied for tasks in a medical setting. 
Finally, \cref{part:discussion-and-conclusion} contains the discussion and conclusions of the thesis.


\contribitem{part:background}
\Cref{chp:introduction} provides a general introduction to the thesis and gives motivating examples for speech recognition and assistance in medical diagnostics. \Cref{chp:technical-background} provides additional technical background not included in the individual studies by introducing uncertainty as a concept in the context of information and probability theory, introducing the task of out-of-distribution detection and reviewing existing work on the problem, and providing an introduction to variational autoencoders. 


\contribitem{part:unsupervised-uncertainty-estimation}
This part of the thesis is concerned with unsupervised uncertainty estimation and consists of three papers. 
The first two papers are concerned with out-of-distribution detection using generative models. The first paper proposes a new method for out-of-distribution detection using hierarchical variational autoencoders. 
The second paper builds on the first and proposes a model-agnostic method for out-of-distribution detection that can be used with any differentiable generative model with explicit likelihood. 
The third paper proposes a new hierarchical variational autoencoder for speech and benchmarks it against other variational autoencoders and autoregressive models.

\contribitem{chp:paper-hierarchical}
This paper proposes a new method for unsupervised out-of-distribution detection using hierarchical variational autoencoders. 
The paper provides evidence that the failure of deep generative models to assign lower likelihoods to data from outside the training distribution is due to overemphasis on low-level features that generalize between distributions. 
To solve this, the proposed method computes a likelihood-ratio score for out-of-distribution detection that requires data to be in-distribution across all feature-levels. 
The proposed method is computationally efficient, fully unsupervised, and performs well on several out-of-distribution detection benchmarks. 
% Methods like this are important for the development of safe and reliable machine learning systems, especially in medical applications where the consequences of errors can be significant. 

\contribitem{chp:paper-modelagnostic}
This paper proposes a model-agnostic method for out-of-distribution detection that can be used with any differentiable, explicit likelihood generative model. 
The method is based on combining a classical parametric test with the recently introduced typicality test via Fisher's method. 
We show that this leads to a more accurate out-of-distribution test. We also discuss the benefits of casting out-of-distribution detection as a statistical testing problem, for instance enabling false positive rate control which is valuable for practical applications, especially in high-risk settings such as medical decision-making.

\contribitem{chp:paper-benchmarking}
This paper proposes a new hierarchical variational autoencoder for speech inspired by the Clockwork VAE \cite{saxena_clockwork_2021}. 
The model is benchmarked against other variational autoencoders and autoregressive models for speech. We show that using a hierarchy of latent variables improves the likelihood of the model and that the learned latent space captures information relevant for speech recognition such as phonetic content.


\contribitem{part:self-supervised-speech-representation-learning}
This part of the thesis is concerned with self-supervised speech representation learning and consists of a single paper that provides a substantial review of the field \cite{mohamed_selfsupervised_2022}. 
Self-supervised learning is a promising approach to speech representation learning that has shown a fast, wide and successful adoption across speech modelling over the course of the last few years. 
As measured by performance on common downstream tasks such as speech recognition and spoken language understanding, self-supervised representations generally outperform representations learned via probabilistic generative models such as those investigated in \cref{part:unsupervised-uncertainty-estimation}. 
In this review paper, we do not consider uncertainty estimation, but in future work, consideration should be given to the use of self-supervised learning as an alternative paradigm to generative models for learning representations for unsupervised uncertainty estimation. We shall return to this in the discussion of \cref{chp:paper-review} in \cref{sec:discussion-paper-review}.

\contribitem{chp:paper-review}
This paper provides a comprehensive review of self-supervised speech representation learning. Previous work is grouped into three main categories of methods: contrastive, autoregressive, and generative, and the methods are compared in terms of their training objectives, model architectures, and performance on downstream tasks. The review also provides a discussion of the current state of the field and promising future directions of research. 

An early version of this review paper \cite{borgholt_brief_2022} included a review of generative latent variable models for speech representation learning and a comparison between the two modelling paradigms. 
Due to the superior performance of self-supervised methods and a desire to focus on self-supervised methods, the paper in \cref{chp:paper-review} does not focus on generative latent variable models. 
The early version is included in \cref{app:paper-brief} for reference.

 
\contribitem{part:medical-applications}
This part contains studies on machine learning methods applied for tasks in a medical setting. While uncertainty estimation is not a central theme to any of the two papers, the first paper performs a substantial evaluation of the explainability of the proposed model via an occlusion analysis on the text input. Later, in the discussion, we shall further consider uncertainty estimation in relation to these two papers.
\todo[inline]{Revise and add more details to this section.}

\contribitem{chp:paper-retrospective}
Effective stroke treatment depends on recognition by call-takers at prehospital telehealth services. This paper aimed to develop and assess the potential of machine learning in improving prehospital stroke recognition during medical helpline calls. 
We used calls from Copenhagen during 2015 to 2020, to develop a machine learning-based classification pipeline. First, calls were transcribed by a speech recognition model and then categorised as stroke or non-stroke using a text classification model.
On test data from 2021, call-takers achieved an overall sensitivity of 52.7\% (95\% confidence interval 49.2-56.4\%) with a positive predictive value (PPV) of 17.1\% (15.5-18.6\%) while the machine learning framework performed significantly better (p < 0.0001) with a sensitivity of 63.0\% (62.0-64.1\%) and a PPV of 24.9\% (24.3-25.5\%).
This study provides preliminary evidence that a machine learning framework for recognizing stroke in prehospital medical helpline calls could become a supportive tool for call-takers, aiding in early and accurate stroke recognition.

\contribitem{chp:paper-automated}
Improving the efficiency of medical coding can alleviate the administrative burden on medical staff and help reduce the rising costs for hospitals. 
In this paper, we review the current state-of-the-art in automated medical coding of clinical notes. 
We reproduce, analyze and compare several models on the MIMIC-III dataset showing that poor performance is often attributable to weak configuration, crudely sampled train-test splits, and insufficient evaluation. 
We compare models on data splits created with stratified sampling, use identical experimental setups and tune hyperparameters and decision boundaries. 
By analyzing prediction errors, we confirm that all models struggle with rare codes, while long documents only have a negligible impact. 
We also present the first comprehensive results on the newly released MIMIC-IV dataset using the reproduced models. 
This paper aims to increase reproducibility and comparability of future work in automated medical coding and to provide a baseline for future research. 
