{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda env create --force -f environment.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter: RuntimeWarning: invalid value encountered in divide\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"invalid value encountered in divide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-v0_8-deep\")\n",
    "\n",
    "font = {\"family\": \"serif\", \"size\": 14}\n",
    "\n",
    "matplotlib.rc(\"font\", **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_ensemble_test = pd.read_csv(\"./delivery_1_cv_v7_seeds/split_v7_2021_test_cc_dispatcher_precision_recall_harmonic_mean_median_ensemble_individual_predictions.csv\")\n",
    "median_ensemble_val = pd.read_csv(\"./delivery_1_cv_v7_seeds/split_v7_2021_test_cc_dispatcher_precision_recall_harmonic_mean_median_ensemble_individual_predictions_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ensembles_test = pd.read_csv(\"./delivery_1_cv_v7_seeds/split_v7_2021_test_cc_dispatcher_precision_recall_harmonic_mean_predictions.csv\")\n",
    "all_ensembles_val = pd.read_csv(\"./delivery_1_cv_v7_seeds/split_v7_2021_test_cc_dispatcher_precision_recall_harmonic_mean_predictions_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_map = {\n",
    "    \"logits 20\": \"logits 1\",\n",
    "    \"logits 21\": \"logits 2\",\n",
    "    \"logits 22\": \"logits 3\",\n",
    "    \"logits 23\": \"logits 4\",\n",
    "    \"logits 24\": \"logits 5\",\n",
    "    \"probs 20\": \"probs 1\",\n",
    "    \"probs 21\": \"probs 2\",\n",
    "    \"probs 22\": \"probs 3\",\n",
    "    \"probs 23\": \"probs 4\",\n",
    "    \"probs 24\": \"probs 5\",\n",
    "}\n",
    "median_ensemble_test.rename(columns=column_map, inplace=True)\n",
    "median_ensemble_test[\"ensemble_preds\"] = median_ensemble_test[\"ensemble_probs\"] > 0.5\n",
    "\n",
    "median_ensemble_val.rename(columns=column_map, inplace=True)\n",
    "median_ensemble_val[\"ensemble_preds\"] = median_ensemble_val[\"ensemble_probs\"] > 0.5\n",
    "\n",
    "median_ensemble_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import (column_or_1d)\n",
    "from sklearn.utils.validation import check_consistent_length, _check_pos_label_consistency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration_curve(\n",
    "    y_true,\n",
    "    y_prob,\n",
    "    *,\n",
    "    pos_label=None,\n",
    "    n_bins=5,\n",
    "    strategy=\"uniform\",\n",
    "):\n",
    "    \"\"\"Compute true and predicted probabilities for a calibration curve.\n",
    "\n",
    "    The method assumes the inputs come from a binary classifier, and\n",
    "    discretize the [0, 1] interval into bins.\n",
    "\n",
    "    Calibration curves may also be referred to as reliability diagrams.\n",
    "\n",
    "    Read more in the :ref:`User Guide <calibration>`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like of shape (n_samples,)\n",
    "        True targets.\n",
    "\n",
    "    y_prob : array-like of shape (n_samples,)\n",
    "        Probabilities of the positive class.\n",
    "\n",
    "    pos_label : int, float, bool or str, default=None\n",
    "        The label of the positive class.\n",
    "\n",
    "        .. versionadded:: 1.1\n",
    "\n",
    "    n_bins : int, default=5\n",
    "        Number of bins to discretize the [0, 1] interval. A bigger number\n",
    "        requires more data. Bins with no samples (i.e. without\n",
    "        corresponding values in `y_prob`) will not be returned, thus the\n",
    "        returned arrays may have less than `n_bins` values.\n",
    "\n",
    "    strategy : {'uniform', 'quantile'}, default='uniform'\n",
    "        Strategy used to define the widths of the bins.\n",
    "\n",
    "        uniform\n",
    "            The bins have identical widths.\n",
    "        quantile\n",
    "            The bins have the same number of samples and depend on `y_prob`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    prob_true : ndarray of shape (n_bins,) or smaller\n",
    "        The proportion of samples whose class is the positive class, in each\n",
    "        bin (fraction of positives).\n",
    "\n",
    "    prob_pred : ndarray of shape (n_bins,) or smaller\n",
    "        The mean predicted probability in each bin.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Alexandru Niculescu-Mizil and Rich Caruana (2005) Predicting Good\n",
    "    Probabilities With Supervised Learning, in Proceedings of the 22nd\n",
    "    International Conference on Machine Learning (ICML).\n",
    "    See section 4 (Qualitative Analysis of Predictions).\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import numpy as np\n",
    "    >>> from sklearn.calibration import calibration_curve\n",
    "    >>> y_true = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
    "    >>> y_pred = np.array([0.1, 0.2, 0.3, 0.4, 0.65, 0.7, 0.8, 0.9,  1.])\n",
    "    >>> prob_true, prob_pred = calibration_curve(y_true, y_pred, n_bins=3)\n",
    "    >>> prob_true\n",
    "    array([0. , 0.5, 1. ])\n",
    "    >>> prob_pred\n",
    "    array([0.2  , 0.525, 0.85 ])\n",
    "    \"\"\"\n",
    "    y_true = column_or_1d(y_true)\n",
    "    y_prob = column_or_1d(y_prob)\n",
    "    check_consistent_length(y_true, y_prob)\n",
    "    pos_label = _check_pos_label_consistency(pos_label, y_true)\n",
    "\n",
    "    if y_prob.min() < 0 or y_prob.max() > 1:\n",
    "        raise ValueError(\"y_prob has values outside [0, 1].\")\n",
    "\n",
    "    labels = np.unique(y_true)\n",
    "    if len(labels) > 2:\n",
    "        raise ValueError(\n",
    "            f\"Only binary classification is supported. Provided labels {labels}.\"\n",
    "        )\n",
    "    y_true = y_true == pos_label\n",
    "\n",
    "    if isinstance(n_bins, (list, np.ndarray)):\n",
    "        bins = np.asarray(n_bins)\n",
    "        if (bins < 0).any() or (bins > 1).any():\n",
    "            raise ValueError(\"n_bins must be between 0 and 1\")\n",
    "        if (bins[:-1] >= bins[1:]).any():\n",
    "            raise ValueError(\"bins must increase monotonically\")\n",
    "    elif strategy == \"quantile\":  # Determine bin edges by distribution of data\n",
    "        quantiles = np.linspace(0, 1, n_bins + 1)\n",
    "        bins = np.percentile(y_prob, quantiles * 100)\n",
    "    elif strategy == \"uniform\":\n",
    "        bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid entry to 'strategy' input. Strategy \"\n",
    "            \"must be either 'quantile' or 'uniform'.\"\n",
    "        )\n",
    "\n",
    "    binids = np.searchsorted(bins[1:-1], y_prob)\n",
    "\n",
    "    bin_sums = np.bincount(binids, weights=y_prob, minlength=len(bins))\n",
    "    bin_true = np.bincount(binids, weights=y_true, minlength=len(bins))\n",
    "    bin_total = np.bincount(binids, minlength=len(bins))\n",
    "\n",
    "    # nonzero = bin_total != 0\n",
    "    # prob_true = bin_true[nonzero] / bin_total[nonzero]\n",
    "    # prob_pred = bin_sums[nonzero] / bin_total[nonzero]\n",
    "    \n",
    "    prob_true = bin_true / bin_total\n",
    "    prob_pred = bin_sums / bin_total\n",
    "\n",
    "    return prob_true, prob_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(arrays: List[np.ndarray], labels: List, **kwargs):\n",
    "    \n",
    "    density = kwargs.get(\"density\", False)\n",
    "    fig, ax = plt.subplots(figsize=(6.4, 4.8))\n",
    "\n",
    "    for array, label in zip(arrays, labels):\n",
    "        ax.hist(array, bins=kwargs.get(\"bins\", 50), alpha=kwargs.get(\"alpha\", 0.5), label=label, density=density)\n",
    "\n",
    "    ax.set_yscale(kwargs.get(\"yscale\", \"log\"))\n",
    "    ax.set_xlabel(\"Predicted probability\")\n",
    "    if density:\n",
    "        ax.set_ylabel(\"Density\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"Count\")\n",
    "    ax.legend()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kde_1d(arrays: List[np.ndarray], labels: List, **kwargs):\n",
    "    fig, ax = plt.subplots(figsize=(6.4, 4.8))\n",
    "\n",
    "    for array, label in zip(arrays, labels):\n",
    "        ax = sns.kdeplot(array, ax=ax, label=label, bw_method=kwargs.get(\"bw_method\", 0.1))\n",
    "\n",
    "    ax.set_xlabel(kwargs.get(\"xlabel\", \"Predicted probability\"))\n",
    "    ax.set_ylabel(kwargs.get(\"ylabel\", \"Log-density\"))\n",
    "    ax.legend()\n",
    "    ax.set_yscale(kwargs.get(\"yscale\", \"log\"))\n",
    "    ax.set_xlim(kwargs.get(\"xlim\", (0, 1)))\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_calibration_curve(targets: List[np.ndarray], model_probs: List[np.ndarray], labels=None, ax=None, **kwargs):\n",
    "    if not isinstance(targets, list):\n",
    "        targets = [targets]\n",
    "    if not isinstance(model_probs, list):\n",
    "        model_probs = [model_probs]\n",
    "\n",
    "    if len(model_probs) != len(targets):\n",
    "        assert len(model_probs) == 1 or len(targets) == 1, \"Number of models and targets must be equal or 1\"\n",
    "        if len(model_probs) == 1:\n",
    "            model_probs = model_probs * len(targets)\n",
    "        else:\n",
    "            targets = targets * len(model_probs)\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6.4, 4.8))\n",
    "        ax.plot([0, 1], [0, 1], \"k:\", label=\"Perfect calibration\")\n",
    "    else:\n",
    "        fig = None\n",
    "\n",
    "    for target, probs, label in zip(targets, model_probs, labels):\n",
    "        prob_true, prob_pred = calibration_curve(\n",
    "            target,\n",
    "            probs,\n",
    "            n_bins=kwargs.get(\"n_bins\", 20),\n",
    "            strategy=kwargs.get(\"strategy\", \"uniform\"),\n",
    "        )\n",
    "        ax.plot(prob_pred, prob_true, marker=\"o\", markersize=3, label=label)\n",
    "\n",
    "    ax.set_xlabel(\"Mean predicted probability\")\n",
    "    ax.set_ylabel(\"Fraction of positives\")\n",
    "    ax.legend()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_calibration_curve(\n",
    "    targets=median_ensemble_test[\"y\"],\n",
    "    model_probs=[median_ensemble_test[\"ensemble_probs\"], median_ensemble_test[\"probs 1\"]],\n",
    "    labels=[\"Ensemble\", \"Single model\"],\n",
    "    n_bins=20,\n",
    ")\n",
    "# fig.savefig(\"calibration_curve_ensemble_and_single_model_uncalibrated.pdf\", bbox_inches=\"tight\")\n",
    "fig, ax = plot_histogram(arrays=[median_ensemble_test[\"ensemble_probs\"], median_ensemble_test[\"probs 1\"]], labels=[\"Ensemble\", \"Constituent model 1\"], bins=30)\n",
    "fig.savefig(\"histogram_ensemble_and_single_model.pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_calibration_curve(\n",
    "    targets=median_ensemble_test[\"y\"],\n",
    "    model_probs=[\n",
    "        median_ensemble_test[\"ensemble_probs\"],\n",
    "        median_ensemble_test[\"probs 1\"],\n",
    "        median_ensemble_test[\"probs 2\"],\n",
    "        median_ensemble_test[\"probs 3\"],\n",
    "        median_ensemble_test[\"probs 4\"],\n",
    "        median_ensemble_test[\"probs 5\"],\n",
    "    ],\n",
    "    labels=[\"Ensemble\", \"Constituent model 1\", \"Constituent model 2\", \"Constituent model 3\", \"Constituent model 4\", \"Constituent model 4\"],\n",
    "    n_bins=20,\n",
    ")\n",
    "fig.savefig(\"calibration_curve_ensemble_and_all_models_uncalibrated.pdf\", bbox_inches=\"tight\")\n",
    "plot_histogram(\n",
    "    arrays=[\n",
    "        median_ensemble_test[\"ensemble_probs\"],\n",
    "        median_ensemble_test[\"probs 1\"],\n",
    "        median_ensemble_test[\"probs 2\"],\n",
    "        median_ensemble_test[\"probs 3\"],\n",
    "        median_ensemble_test[\"probs 4\"],\n",
    "        median_ensemble_test[\"probs 5\"],\n",
    "    ],\n",
    "    labels=[\"Ensemble\", \"Constituent model 1\", \"Constituent model 2\", \"Constituent model 3\", \"Constituent model 4\", \"Constituent model 4\"],\n",
    "    alpha=0.3\n",
    ")\n",
    "\n",
    "fig, ax = plot_kde_1d(\n",
    "    arrays=[\n",
    "        median_ensemble_test[\"ensemble_probs\"],\n",
    "        median_ensemble_test[\"probs 1\"],\n",
    "        median_ensemble_test[\"probs 2\"],\n",
    "        median_ensemble_test[\"probs 3\"],\n",
    "        median_ensemble_test[\"probs 4\"],\n",
    "        median_ensemble_test[\"probs 5\"],\n",
    "    ],\n",
    "    labels=[\"Ensemble\", \"Constituent model 1\", \"Constituent model 2\", \"Constituent model 3\", \"Constituent model 4\", \"Constituent model 4\"],\n",
    ")\n",
    "fig.savefig(\"kde_ensemble_and_all_models.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_male = median_ensemble_test[\"gender\"] == \"M\"\n",
    "is_female = median_ensemble_test[\"gender\"] == \"K\"\n",
    "plot_calibration_curve(\n",
    "    targets=[median_ensemble_test[\"y\"][is_male], median_ensemble_test[\"y\"][is_female]],\n",
    "    model_probs=[median_ensemble_test[\"ensemble_probs\"][is_male], median_ensemble_test[\"ensemble_probs\"][is_female]],\n",
    "    labels=[\"Male\", \"Female\"],\n",
    "    n_bins=20,\n",
    ")\n",
    "plot_histogram(\n",
    "    arrays=[median_ensemble_test[\"ensemble_probs\"][is_male], median_ensemble_test[\"ensemble_probs\"][is_female]],\n",
    "    labels=[\"Male\", \"Female\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = median_ensemble_test[\"h\"]\n",
    "\n",
    "plot_calibration_curve(\n",
    "    targets=[median_ensemble_test[\"y\"][condition], median_ensemble_test[\"y\"][~condition]],\n",
    "    model_probs=[median_ensemble_test[\"ensemble_probs\"][condition], median_ensemble_test[\"ensemble_probs\"][~condition]],\n",
    "    labels=[\"Call-taker recognition\", \"No call-taker recognition\"],\n",
    "    n_bins=20,\n",
    ")\n",
    "plot_histogram(\n",
    "    arrays=[median_ensemble_test[\"ensemble_probs\"][condition], median_ensemble_test[\"ensemble_probs\"][~condition]],\n",
    "    labels=[\"Call-taker recognition\", \"No call-taker recognition\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(\n",
    "    arrays=[median_ensemble_test[\"ensemble_probs\"][condition]],\n",
    "    labels=[\"Call-taker recognition\"],\n",
    "    yscale=\"linear\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = median_ensemble_test[\"h\"] == median_ensemble_test[\"ensemble_preds\"]\n",
    "\n",
    "plot_calibration_curve(\n",
    "    targets=[median_ensemble_test[\"y\"][condition], median_ensemble_test[\"y\"][~condition]],\n",
    "    model_probs=[median_ensemble_test[\"ensemble_probs\"][condition], median_ensemble_test[\"ensemble_probs\"][~condition]],\n",
    "    labels=[\"Model/call-taker agreement\", \"Model/call-taker disagreement\"],\n",
    "    n_bins=20,\n",
    ")\n",
    "plot_histogram(\n",
    "    arrays=[median_ensemble_test[\"ensemble_probs\"][condition], median_ensemble_test[\"ensemble_probs\"][~condition]],\n",
    "    labels=[\"Model/call-taker agreement\", \"Model/call-taker disagreement\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_old = median_ensemble_test[\"age\"] >= 65\n",
    "plot_calibration_curve(\n",
    "    targets=[median_ensemble_test[\"y\"][is_old], median_ensemble_test[\"y\"][~is_old]],\n",
    "    model_probs=[median_ensemble_test[\"ensemble_probs\"][is_old], median_ensemble_test[\"ensemble_probs\"][~is_old]],\n",
    "    labels=[\"65+\", \"18-65\"],\n",
    "    n_bins=20,\n",
    ")\n",
    "plot_histogram(\n",
    "    arrays=[median_ensemble_test[\"ensemble_probs\"][is_old], median_ensemble_test[\"ensemble_probs\"][~is_old]],\n",
    "    labels=[\"65+\", \"18-65\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = median_ensemble_test[\"y\"]\n",
    "\n",
    "plot_calibration_curve(\n",
    "    targets=[median_ensemble_test[\"y\"][condition], median_ensemble_test[\"y\"][~condition]],\n",
    "    model_probs=[median_ensemble_test[\"ensemble_probs\"][condition], median_ensemble_test[\"ensemble_probs\"][~condition]],\n",
    "    labels=[\"Model/call-taker agreement\", \"Model/call-taker disagreement\"],\n",
    "    n_bins=20,\n",
    ")\n",
    "plot_histogram(\n",
    "    arrays=[median_ensemble_test[\"ensemble_probs\"][condition], median_ensemble_test[\"ensemble_probs\"][~condition]],\n",
    "    labels=[\"Model/call-taker agreement\", \"Model/call-taker disagreement\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Platt scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(penalty=\"none\", fit_intercept=True)\n",
    "logistic.fit(median_ensemble_val[\"ensemble_probs\"].to_numpy()[:, np.newaxis], median_ensemble_val[\"y\"].to_numpy())\n",
    "ensemble_probs_logistic = logistic.predict_proba(median_ensemble_test[\"ensemble_probs\"].to_numpy()[:, np.newaxis])[:, 1]\n",
    "ensemble_probs_logistic_val = logistic.predict_proba(median_ensemble_val[\"ensemble_probs\"].to_numpy()[:, np.newaxis])[:, 1]\n",
    "\n",
    "individual_probs_logistic = []\n",
    "individual_probs_logistic_val = []\n",
    "for i in range(1, 6):\n",
    "    logistic_i = LogisticRegression(penalty=\"none\", fit_intercept=True)\n",
    "    logistic_i.fit(median_ensemble_val[f\"probs {i}\"].to_numpy()[:, np.newaxis], median_ensemble_val[\"y\"].to_numpy())\n",
    "    individual_probs_logistic += [logistic_i.predict_proba(median_ensemble_test[f\"probs {i}\"].to_numpy()[:, np.newaxis])[:, 1]]\n",
    "    individual_probs_logistic_val += [logistic_i.predict_proba(median_ensemble_val[f\"probs {i}\"].to_numpy()[:, np.newaxis])[:, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic.predict_proba(np.array([[0.8]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic.coef_, logistic.intercept_, logistic.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot logistic sigmoid fit\n",
    "x = np.linspace(0, 1, 200)\n",
    "y = logistic.predict_proba(x[:, np.newaxis])[:, 1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6.4, 4.8))\n",
    "ax.plot([0, 1], [0, 1], \"k:\", label=\"Perfect calibration\")\n",
    "ax.plot(x, y, label=\"Logistic sigmoid fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_calibration_curve(\n",
    "    targets=median_ensemble_val[\"y\"],\n",
    "    model_probs=[ensemble_probs_logistic_val, *individual_probs_logistic_val],\n",
    "    labels=[\"Ensemble\"],#, *[\"Constituent model\"] * 5],\n",
    "    n_bins=20,\n",
    ")\n",
    "plot_histogram(arrays=[ensemble_probs_logistic_val], labels=[\"Ensemble\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_calibration_curve(\n",
    "    targets=median_ensemble_test[\"y\"],\n",
    "    # model_probs=[ensemble_probs_logistic, *individual_probs_logistic],\n",
    "    model_probs=[ensemble_probs_logistic, *individual_probs_logistic],\n",
    "    labels=[\"Ensemble\"], #, *[\"Constituent model\"] * 5],\n",
    "    n_bins=20,\n",
    "    strategy=\"uniform\",\n",
    "    # n_bins=1000,\n",
    "    # strategy=\"quantile\",\n",
    ")\n",
    "fig.savefig(\"calibration_curve_ensemble_logistic.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isotonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isotonic = IsotonicRegression(y_min=0, y_max=1, increasing=True, out_of_bounds=\"clip\")\n",
    "isotonic.fit(median_ensemble_val[\"ensemble_probs\"].to_numpy(), median_ensemble_val[\"y\"].to_numpy())\n",
    "ensemble_probs_isotonic = isotonic.transform(median_ensemble_test[\"ensemble_probs\"].to_numpy())\n",
    "ensemble_probs_isotonic_val = isotonic.transform(median_ensemble_val[\"ensemble_probs\"].to_numpy())\n",
    "\n",
    "individual_probs_isotonic = []\n",
    "individual_probs_isotonic_val = []\n",
    "for i in range(1, 6):\n",
    "    isotonic_i = IsotonicRegression(y_min=0, y_max=1, increasing=True, out_of_bounds=\"clip\")\n",
    "    isotonic_i.fit(median_ensemble_val[f\"probs {i}\"].to_numpy(), median_ensemble_val[\"y\"].to_numpy())\n",
    "    individual_probs_isotonic += [isotonic_i.transform(median_ensemble_test[f\"probs {i}\"].to_numpy())]\n",
    "    individual_probs_isotonic_val += [isotonic_i.transform(median_ensemble_val[f\"probs {i}\"].to_numpy())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isotonic.X_thresholds_[-10:], isotonic.y_thresholds_[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_ensemble_test[\"ensemble_probs\"].sort_values().to_numpy()[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(arrays=[ensemble_probs_isotonic, ensemble_probs_isotonic_val], labels=[\"Ensemble test\", \"Ensemble validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 200)\n",
    "y = isotonic.transform(x)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6.4, 4.8))\n",
    "ax.plot([0, 1], [0, 1], \"k:\", label=\"Perfect calibration\")\n",
    "# ax.plot(isotonic.X_thresholds_, isotonic.y_thresholds_, \"-\", marker=\"o\", markersize=3, label=\"Isotonic\")\n",
    "ax.plot(x, y, label=\"Isotonic fit\")\n",
    "\n",
    "val_pos = median_ensemble_val[\"ensemble_probs\"][median_ensemble_val[\"y\"] == 1]\n",
    "val_neg = median_ensemble_val[\"ensemble_probs\"][median_ensemble_val[\"y\"] == 0]\n",
    "plot_histogram(arrays=[val_neg, val_pos], labels=[\"Ensemble probs (val-neg)\", \"Ensemble probs (val-pos)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_calibration_curve(\n",
    "    targets=median_ensemble_val[\"y\"],\n",
    "    model_probs=[ensemble_probs_isotonic_val, *individual_probs_isotonic_val],\n",
    "    labels=[\"Ensemble\"],#, *[\"Constituent model\"] * 5],\n",
    "    n_bins=10,\n",
    "    strategy=\"uniform\",\n",
    "    # n_bins=1000,\n",
    "    # strategy=\"quantile\",\n",
    ")\n",
    "plot_histogram(arrays=[ensemble_probs_isotonic_val], labels=[\"Ensemble\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_ensemble_test[\"y\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_probs_isotonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_calibration_curve(\n",
    "    targets=median_ensemble_test[\"y\"],\n",
    "    model_probs=[ensemble_probs_isotonic, *individual_probs_isotonic],\n",
    "    labels=[\"Ensemble\"],#, *[\"Constituent model\"] * 5],\n",
    "    # n_bins=10,\n",
    "    # strategy=\"uniform\",\n",
    "    n_bins=1000,\n",
    "    strategy=\"quantile\",\n",
    ")\n",
    "plot_histogram(arrays=[ensemble_probs_isotonic], labels=[\"Ensemble\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(8, 8), activation=\"tanh\", solver=\"adam\", max_iter=3000, random_state=0)\n",
    "mlp.out_activation_ = \"sigmoid\"\n",
    "mlp.fit(median_ensemble_val[\"ensemble_probs\"].to_numpy()[:, np.newaxis], median_ensemble_val[\"y\"].to_numpy()[:, np.newaxis])\n",
    "ensemble_probs_mlp = mlp.predict(median_ensemble_test[\"ensemble_probs\"].to_numpy()[:, np.newaxis]).clip(0)\n",
    "ensemble_probs_mlp_val = mlp.predict(median_ensemble_val[\"ensemble_probs\"].to_numpy()[:, np.newaxis]).clip(0)\n",
    "\n",
    "individual_probs_mlp = []\n",
    "individual_probs_mlp_val = []\n",
    "for i in range(1, 6):\n",
    "    mlp_i = MLPRegressor(hidden_layer_sizes=(8, 8), activation=\"tanh\", solver=\"adam\", max_iter=3000, random_state=0)\n",
    "    mlp_i.out_activation_ = \"sigmoid\"\n",
    "    mlp_i.fit(median_ensemble_val[f\"probs {i}\"].to_numpy()[:, np.newaxis], median_ensemble_val[\"y\"].to_numpy()[:, np.newaxis])\n",
    "    individual_probs_mlp += [mlp_i.predict(median_ensemble_test[f\"probs {i}\"].to_numpy()[:, np.newaxis]).clip(0)]\n",
    "    individual_probs_mlp_val += [mlp_i.predict(median_ensemble_val[f\"probs {i}\"].to_numpy()[:, np.newaxis]).clip(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(arrays=[ensemble_probs_mlp, ensemble_probs_mlp_val], labels=[\"Ensemble test\", \"Ensemble validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_calibration_curve(\n",
    "    targets=median_ensemble_val[\"y\"],\n",
    "    model_probs=[ensemble_probs_mlp_val, *individual_probs_mlp_val],\n",
    "    labels=[\"Ensemble\"],#, *[\"Constituent model\"] * 5],\n",
    "    n_bins=15,\n",
    "    strategy=\"uniform\",\n",
    "    # n_bins=1000,\n",
    "    # strategy=\"quantile\",\n",
    ")\n",
    "plot_histogram(arrays=[ensemble_probs_mlp_val], labels=[\"Ensemble\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_calibration_curve(\n",
    "    targets=median_ensemble_test[\"y\"],\n",
    "    model_probs=[ensemble_probs_mlp, *individual_probs_mlp],\n",
    "    labels=[\"Ensemble\"],#, *[\"Constituent model\"] * 5],\n",
    "    # n_bins=10,\n",
    "    # strategy=\"uniform\",\n",
    "    n_bins=1000,\n",
    "    strategy=\"quantile\",\n",
    ")\n",
    "plot_histogram(arrays=[ensemble_probs_mlp], labels=[\"Ensemble\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot-making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pow2_bin_edges(num_bins: int, min_val: float = 0.0, max_val: float = 1.0):\n",
    "    bin_edges = [i**2 for i in range(1, num_bins, 1)] #np.linspace(0, 1, num_bins + 1)\n",
    "    bin_edges = np.array(bin_edges) / (num_bins + 1) ** 2\n",
    "    bin_edges = np.concatenate([[0.0], bin_edges, [1.0]])\n",
    "    bin_edges = bin_edges * (max_val - min_val) + min_val\n",
    "    return bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pow2_bin_edges(10), get_pow2_bin_edges(10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All calibration fits\n",
    "\n",
    "# Logistic sigmoid\n",
    "x_logistic = np.linspace(0, 1, 200)\n",
    "y_logistic = logistic.predict_proba(x_logistic[:, np.newaxis])[:, 1]\n",
    "\n",
    "# Isothonic regression\n",
    "x_isotonic = np.linspace(0, 1, 200)\n",
    "y_isotonic = isotonic.transform(x_isotonic)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6.4, 4.8))\n",
    "ax.plot([0, 1], [0, 1], label=\"Uncalibrated\")\n",
    "ax.plot(x_logistic, y_logistic, label=\"Logistic fit\")\n",
    "ax.plot(x_isotonic, y_isotonic, \"-\", label=\"Isotonic fit\")\n",
    "ax.set_xlabel(\"Predicted probability\")\n",
    "ax.set_ylabel(\"Calibrated probability\")\n",
    "ax.legend()\n",
    "fig.savefig(\"calibration_fits_ensemble.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All calibration curves\n",
    "arrays = [median_ensemble_test[\"ensemble_probs\"], ensemble_probs_logistic, ensemble_probs_isotonic]#, ensemble_probs_mlp]\n",
    "labels = [\"Ensemble uncalibrated\", \"Ensemble logistic calibration\", \"Ensemble isotonic calibration\", \"Ensemble MLP calibration\"]\n",
    "\n",
    "fig, ax = plot_calibration_curve(\n",
    "    targets=median_ensemble_test[\"y\"],\n",
    "    model_probs=arrays[0:1],\n",
    "    labels=labels[0:1], #, *[\"Constituent model\"] * 5],\n",
    "    n_bins=20,\n",
    "    strategy=\"uniform\",\n",
    ")\n",
    "\n",
    "plot_calibration_curve(\n",
    "    targets=median_ensemble_test[\"y\"],\n",
    "    model_probs=arrays[1:],\n",
    "    labels=labels[1:], #, *[\"Constituent model\"] * 5],\n",
    "    n_bins=1000,\n",
    "    strategy=\"quantile\",\n",
    "    ax=ax,\n",
    ")\n",
    "fig.savefig(\"calibration_curves_ensemble.pdf\", bbox_inches=\"tight\")\n",
    "plot_histogram(arrays=arrays, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All calibration curves\n",
    "arrays = [median_ensemble_test[\"ensemble_probs\"], ensemble_probs_logistic, ensemble_probs_isotonic]#, ensemble_probs_mlp]\n",
    "labels = [\"Ensemble uncalibrated\", \"Ensemble logistic calibration\", \"Ensemble isotonic calibration\", \"Ensemble MLP calibration\"]\n",
    "\n",
    "fig, ax = plot_calibration_curve(\n",
    "    targets=median_ensemble_test[\"y\"],\n",
    "    model_probs=arrays[0:1],\n",
    "    labels=labels[0:1], #, *[\"Constituent model\"] * 5],\n",
    "    n_bins=20,\n",
    "    strategy=\"uniform\",\n",
    ")\n",
    "\n",
    "plot_calibration_curve(\n",
    "    targets=median_ensemble_test[\"y\"],\n",
    "    model_probs=arrays[1:],\n",
    "    labels=labels[1:], #, *[\"Constituent model\"] * 5],\n",
    "    n_bins=get_pow2_bin_edges(7),\n",
    "    ax=ax,\n",
    ")\n",
    "# fig.savefig(\"calibration_curves_ensemble.pdf\", bbox_inches=\"tight\")\n",
    "plot_histogram(arrays=arrays, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brier scores\n",
    "brier_scores = {\n",
    "    \"uncalibrated\": sklearn.metrics.brier_score_loss(median_ensemble_test[\"y\"], median_ensemble_test[\"ensemble_probs\"]),\n",
    "    \"logistic\": sklearn.metrics.brier_score_loss(median_ensemble_test[\"y\"], ensemble_probs_logistic),\n",
    "    \"isotonic\": sklearn.metrics.brier_score_loss(median_ensemble_test[\"y\"], ensemble_probs_isotonic),\n",
    "    # \"mlp\": sklearn.metrics.brier_score_loss(median_ensemble_test[\"y\"], ensemble_probs_mlp),\n",
    "    \"average\": sklearn.metrics.brier_score_loss(median_ensemble_test[\"y\"], median_ensemble_test[\"y\"].mean()[np.newaxis].repeat(len(median_ensemble_test))),\n",
    "}\n",
    "print(\"Brier scores: \", brier_scores)\n",
    "\n",
    "# Brier skill scores\n",
    "# - uncalibrated reference\n",
    "brier_skill_scores_uncalibrated = {\n",
    "    \"logistic\": 1 - brier_scores[\"logistic\"] / brier_scores[\"uncalibrated\"],\n",
    "    \"isotonic\": 1 - brier_scores[\"isotonic\"] / brier_scores[\"uncalibrated\"],\n",
    "    # \"mlp\": 1 - brier_scores[\"mlp\"] / brier_scores[\"uncalibrated\"],\n",
    "}\n",
    "print(\"BSS uncalibrated reference: \", brier_skill_scores_uncalibrated)\n",
    "\n",
    "# - average target reference\n",
    "brier_skill_scores_mean = {\n",
    "    \"logistic\": 1 - brier_scores[\"logistic\"] / brier_scores[\"average\"],\n",
    "    \"isotonic\": 1 - brier_scores[\"isotonic\"] / brier_scores[\"average\"],\n",
    "    # \"mlp\": 1 - brier_scores[\"mlp\"] / brier_scores[\"average\"],\n",
    "}\n",
    "print(\"BSS mean reference: \", brier_skill_scores_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1-score of model and call-taker as function of model output probabilities\n",
    "\n",
    "def plot_f1_score_vs_probabilities(targets, model_probs, model_preds, human_preds, model_label: str, target_label: str = \"Call-taker\", num_bins: int = 10):\n",
    "\n",
    "    bin_edges = get_pow2_bin_edges(num_bins)\n",
    "    hist, bin_edges = np.histogram(model_probs, bins=bin_edges)\n",
    "    print(\"Bin edges: \", bin_edges)\n",
    "\n",
    "    bin_widths = bin_edges[1:] - bin_edges[:-1]\n",
    "\n",
    "    fig1 = plt.figure(figsize=(6.4, 4.8))\n",
    "    ax1 = fig1.gca()\n",
    "    ax1.bar(bin_edges[:-1], hist, width=bin_widths, align=\"edge\", alpha=0.5, label=model_label)\n",
    "    ax1.set_yscale(\"log\")\n",
    "    ax1.set_xlabel(\"Predicted probability\")\n",
    "    ax1.set_ylabel(\"Count\")\n",
    "\n",
    "    f1s_model = []\n",
    "    f1s_calltaker = []\n",
    "    for low, high in zip(bin_edges[:-1], bin_edges[1:]):\n",
    "        cond = (model_probs >= low) & (model_probs < high)\n",
    "        \n",
    "        f1_score = sklearn.metrics.f1_score(targets[cond], model_preds[cond])\n",
    "        f1s_model.append(f1_score)\n",
    "        \n",
    "        f1_score_calltaker = sklearn.metrics.f1_score(targets[cond], human_preds[cond])\n",
    "        f1s_calltaker.append(f1_score_calltaker)\n",
    "\n",
    "    f1s_model = np.array(f1s_model)\n",
    "    f1s_calltaker = np.array(f1s_calltaker)\n",
    "\n",
    "    fig2 = plt.figure(figsize=(6.4, 4.8))\n",
    "    ax2 = fig2.gca()\n",
    "\n",
    "    ax2.bar(bin_edges[:-1], f1s_model, width=bin_widths, align=\"edge\", alpha=0.5, label=model_label)\n",
    "    ax2.bar(bin_edges[:-1], f1s_calltaker, width=bin_widths, align=\"edge\", alpha=0.5, label=target_label)\n",
    "\n",
    "    ax2.set_ylabel(\"F1-score\")\n",
    "\n",
    "    ax2.set_xlabel(\"Predicted probability\")\n",
    "    ax2.legend(loc=\"upper left\")\n",
    "    return (fig1, ax1), (fig2, ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f1_score_vs_probabilities(\n",
    "    median_ensemble_test[\"y\"],\n",
    "    median_ensemble_test[\"ensemble_probs\"],\n",
    "    median_ensemble_test[\"ensemble_preds\"],\n",
    "    median_ensemble_test[\"h\"],\n",
    "    \"Uncalibrated ensemble\",\n",
    "    \"Call-taker\",\n",
    "    num_bins=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fig1, ax1), (fig2, ax2) = plot_f1_score_vs_probabilities(\n",
    "    median_ensemble_test[\"y\"],\n",
    "    ensemble_probs_isotonic,\n",
    "    median_ensemble_test[\"ensemble_preds\"],\n",
    "    median_ensemble_test[\"h\"],\n",
    "    \"Calibrated ensemble (isotonic)\",\n",
    "    \"Call-taker\",\n",
    "    num_bins=8\n",
    ")\n",
    "# ax1.set_xlim(0, 0.64)\n",
    "# ax2.set_xlim(0, 0.64)\n",
    "\n",
    "fig1.savefig(\"predicted_probability_histogram.pdf\", bbox_inches=\"tight\")\n",
    "fig2.savefig(\"f1_score_vs_predicted_probability_ensemble_calltaker.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f1_score_vs_probabilities(\n",
    "    median_ensemble_val[\"y\"],\n",
    "    ensemble_probs_isotonic_val,\n",
    "    median_ensemble_val[\"ensemble_preds\"],\n",
    "    median_ensemble_val[\"h\"],\n",
    "    \"Calibrated ensemble (isotonic) [val]\",\n",
    "    \"Call-taker [val]\",\n",
    "    num_bins=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot-making with bootstrap CIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median ensemble\n",
    "human_predictions_test = median_ensemble_test[\"h\"].to_numpy()\n",
    "ensemble_predictions_test = median_ensemble_test[\"ensemble_preds\"].to_numpy()\n",
    "uncalibrated_probabilities_test = median_ensemble_test[f\"ensemble_probs\"].to_numpy()\n",
    "targets_test = median_ensemble_test[\"y\"].to_numpy().astype(int)\n",
    "\n",
    "uncalibrated_probabilities_val = median_ensemble_val[f\"ensemble_probs\"].to_numpy()\n",
    "targets_val = median_ensemble_val[\"y\"].to_numpy().astype(int)\n",
    "\n",
    "# All ensembles\n",
    "# uncalibrated_probabilities_test = [all_ensembles_test[f\"ensemble {i} probs\"] for i in range(1, 12)]\n",
    "# targets_test = [all_ensembles_test[\"y\"]] * 11\n",
    "\n",
    "# uncalibrated_probabilities_val = [all_ensembles_val[f\"ensemble {i} probs\"] for i in range(1, 12)]\n",
    "# targets_val = [all_ensembles_val[\"y\"]] * 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of bootstrap iterations\n",
    "n_bootstrap = 3000\n",
    "\n",
    "uncalibrated_probabilities_val_resampled = []\n",
    "targets_val_sampled = []\n",
    "\n",
    "human_preds_resampled = []\n",
    "model_preds_resampled = []\n",
    "uncalibrated_probabilities_test_resampled = []\n",
    "isotonic_probabilities_test_resampled = []\n",
    "logistic_probabilities_test_resampled = []\n",
    "targets_test_resampled = []\n",
    "\n",
    "isotonic_probabilities_test = isotonic.transform(uncalibrated_probabilities_test)\n",
    "logistic_probabilities_test = logistic.predict_proba(uncalibrated_probabilities_test[:, np.newaxis])[:, 1]\n",
    "\n",
    "bin_edges = get_pow2_bin_edges(10)\n",
    "\n",
    "for _ in tqdm(range(n_bootstrap)):\n",
    "    # Resample the data with replacement\n",
    "    arrays = [targets_test, ensemble_predictions_test, human_predictions_test, uncalibrated_probabilities_test, isotonic_probabilities_test, logistic_probabilities_test]\n",
    "    arrays_resampled = sklearn.utils.resample(*arrays, replace=True)\n",
    "    \n",
    "    targets_test_resampled.append(arrays_resampled[0])\n",
    "    model_preds_resampled.append(arrays_resampled[1])\n",
    "    human_preds_resampled.append(arrays_resampled[2])\n",
    "    uncalibrated_probabilities_test_resampled.append(arrays_resampled[3])\n",
    "    isotonic_probabilities_test_resampled.append(arrays_resampled[4])\n",
    "    logistic_probabilities_test_resampled.append(arrays_resampled[5])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 7\n",
    "\n",
    "uncalibrated_calibration_curves = []\n",
    "isotonic_calibration_curves = []\n",
    "logistic_calibration_curves = []\n",
    "\n",
    "for i in tqdm(range(n_bootstrap)):\n",
    "    uncalibrated_calibration_curve_i = calibration_curve(\n",
    "        targets_test_resampled[i],\n",
    "        uncalibrated_probabilities_test_resampled[i],\n",
    "        n_bins=num_bins,\n",
    "        strategy=\"uniform\",\n",
    "    )\n",
    "    uncalibrated_calibration_curves.append(uncalibrated_calibration_curve_i)\n",
    "    \n",
    "    isotonic_calibration_curve_i = calibration_curve(\n",
    "        targets_test_resampled[i],\n",
    "        isotonic_probabilities_test_resampled[i],\n",
    "        n_bins=get_pow2_bin_edges(num_bins),\n",
    "    )\n",
    "    isotonic_calibration_curves.append(isotonic_calibration_curve_i)\n",
    "    \n",
    "    logistic_calibration_curve_i = calibration_curve(\n",
    "        targets_test_resampled[i],\n",
    "        logistic_probabilities_test_resampled[i],\n",
    "        n_bins=get_pow2_bin_edges(num_bins),\n",
    "    )\n",
    "    logistic_calibration_curves.append(logistic_calibration_curve_i)\n",
    "\n",
    "\n",
    "uncalibrated_calibration_curve = calibration_curve(\n",
    "    targets_test,\n",
    "    uncalibrated_probabilities_test,\n",
    "    n_bins=num_bins,\n",
    "    strategy=\"uniform\",\n",
    ")\n",
    "\n",
    "isotonic_calibration_curve = calibration_curve(\n",
    "    targets_test,\n",
    "    isotonic_probabilities_test,\n",
    "    n_bins=get_pow2_bin_edges(num_bins),\n",
    ")\n",
    "\n",
    "logistic_calibration_curve = calibration_curve(\n",
    "    targets_test,\n",
    "    logistic_probabilities_test,\n",
    "    n_bins=get_pow2_bin_edges(num_bins),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all([c[0].shape == logistic_calibration_curves[0][0].shape for c in logistic_calibration_curves]))\n",
    "print(all([c[0].shape == isotonic_calibration_curves[0][0].shape for c in isotonic_calibration_curves]))\n",
    "print(all([c[0].shape == uncalibrated_calibration_curves[0][0].shape for c in uncalibrated_calibration_curves]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentiles for the confidence intervals\n",
    "def get_calibration_confidence_intervals(calibration_curve: np.ndarray, bootstrap_calibration_curves: List[np.ndarray], alpha: float = 0.05):\n",
    "    lower_bound = np.nanpercentile(bootstrap_calibration_curves, alpha / 2, axis=0)\n",
    "    upper_bound = np.nanpercentile(bootstrap_calibration_curves, 100 - alpha / 2, axis=0)\n",
    "    xerr = np.abs(np.stack([lower_bound[1], upper_bound[1]]) - calibration_curve[1])\n",
    "    yerr = np.abs(np.stack([lower_bound[0], upper_bound[0]]) - calibration_curve[0])\n",
    "    return xerr, yerr\n",
    "\n",
    "\n",
    "uncalibrated_xerr, uncalibrated_yerr = get_calibration_confidence_intervals(uncalibrated_calibration_curve, uncalibrated_calibration_curves, alpha=0.05)\n",
    "isotonic_xerr, isotonic_yerr = get_calibration_confidence_intervals(isotonic_calibration_curve, isotonic_calibration_curves, alpha=0.05)\n",
    "logistic_xerr, logistic_yerr = get_calibration_confidence_intervals(logistic_calibration_curve, logistic_calibration_curves, alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isotonic_yerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6.4, 4.8))\n",
    "ax.plot([0, 1], [0, 1], \"k:\", label=\"Perfect calibration\")\n",
    "\n",
    "# ax.plot(uncalibrated_calibration_curve[1], uncalibrated_calibration_curve[0], marker=\"o\", markersize=3, label=\"Ensemble uncalibrated\")\n",
    "ax.errorbar(\n",
    "    x=uncalibrated_calibration_curve[1],\n",
    "    y=uncalibrated_calibration_curve[0],\n",
    "    xerr=uncalibrated_xerr,\n",
    "    yerr=uncalibrated_yerr,\n",
    "    marker=\"o\",\n",
    "    markersize=3,\n",
    "    capsize=2,\n",
    "    label=\"Ensemble uncalibrated\"\n",
    ")\n",
    "\n",
    "ax.errorbar(\n",
    "    x=logistic_calibration_curve[1],\n",
    "    y=logistic_calibration_curve[0],\n",
    "    xerr=logistic_xerr,\n",
    "    yerr=logistic_yerr,\n",
    "    marker=\"o\",\n",
    "    markersize=3,\n",
    "    capsize=2,\n",
    "    label=\"Ensemble logistic calibration\"\n",
    ")\n",
    "\n",
    "ax.errorbar(\n",
    "    x=isotonic_calibration_curve[1],\n",
    "    y=isotonic_calibration_curve[0],\n",
    "    xerr=isotonic_xerr,\n",
    "    yerr=isotonic_yerr,\n",
    "    marker=\"o\",\n",
    "    markersize=3,\n",
    "    capsize=2,\n",
    "    label=\"Ensemble isotonic calibration\"\n",
    ")\n",
    "ax.set_xlabel(\"Mean predicted probability\")\n",
    "ax.set_ylabel(\"Fraction of positives\")\n",
    "ax.legend()\n",
    "\n",
    "fig.savefig(\"calibration_curves_ensemble_with_cis.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = median_ensemble_test[\"y\"]\n",
    "human_preds = median_ensemble_test[\"h\"]\n",
    "model_preds = median_ensemble_test[\"ensemble_preds\"]\n",
    "model_probs = isotonic_probabilities_test\n",
    "\n",
    "targets_resampled = targets_test_resampled\n",
    "human_preds_resampled = human_preds_resampled\n",
    "model_preds_resampled = model_preds_resampled\n",
    "model_probs_resampled = isotonic_probabilities_test_resampled\n",
    "\n",
    "num_bins = 6\n",
    "bin_edges = get_pow2_bin_edges(num_bins)\n",
    "hist, bin_edges = np.histogram(model_probs, bins=bin_edges)\n",
    "print(\"Bin edges: \", bin_edges)\n",
    "\n",
    "bin_widths = bin_edges[1:] - bin_edges[:-1]\n",
    "\n",
    "# fig1 = plt.figure(figsize=(6.4, 4.8))\n",
    "# ax1 = fig1.gca()\n",
    "# ax1.bar(bin_edges[:-1], hist, width=bin_widths, align=\"edge\", alpha=0.5, label=model_label)\n",
    "# ax1.set_yscale(\"log\")\n",
    "# ax1.set_xlabel(\"Predicted probability\")\n",
    "# ax1.set_ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bootstrap_confidence_intervals_for_scalar(main_estimate: np.ndarray, bootstrap_estimates: List[np.ndarray], alpha: float = 0.05):\n",
    "    lower_bound = np.nanpercentile(bootstrap_estimates, alpha / 2, axis=0)\n",
    "    upper_bound = np.nanpercentile(bootstrap_estimates, 100 - alpha / 2, axis=0)\n",
    "    yerr = np.abs(np.stack([lower_bound, upper_bound]) - main_estimate)\n",
    "    return yerr\n",
    "\n",
    "\n",
    "precision_model = []\n",
    "precision_calltaker = []\n",
    "recall_model = []\n",
    "recall_calltaker = []\n",
    "f1s_model = []\n",
    "f1s_calltaker = []\n",
    "for low, high in zip(bin_edges[:-1], bin_edges[1:]):\n",
    "    cond = (model_probs >= low) & (model_probs < high)\n",
    "    \n",
    "    metrics_model = sklearn.metrics.precision_recall_fscore_support(targets[cond], model_preds[cond], zero_division=np.nan, average=\"binary\", pos_label=1)\n",
    "    metrics_calltaker = sklearn.metrics.precision_recall_fscore_support(targets[cond], human_preds[cond], zero_division=np.nan, average=\"binary\", pos_label=1)\n",
    "    \n",
    "    precision_model.append(metrics_model[0])\n",
    "    precision_calltaker.append(metrics_calltaker[0])\n",
    "    \n",
    "    recall_model.append(metrics_model[1])\n",
    "    recall_calltaker.append(metrics_calltaker[1])\n",
    "    \n",
    "    f1s_model.append(metrics_model[2])\n",
    "    f1s_calltaker.append(metrics_calltaker[2])\n",
    "\n",
    "precision_model = np.array(precision_model)\n",
    "precision_calltaker = np.array(precision_calltaker)\n",
    "\n",
    "recall_model = np.array(recall_model)\n",
    "recall_calltaker = np.array(recall_calltaker)\n",
    "\n",
    "f1s_model = np.array(f1s_model)\n",
    "f1s_calltaker = np.array(f1s_calltaker)\n",
    "\n",
    "\n",
    "bootstrap_precision_model = []\n",
    "bootstrap_precision_calltaker = []\n",
    "bootstrap_recall_model = []\n",
    "bootstrap_recall_calltaker = []\n",
    "bootstrap_f1s_model = []\n",
    "bootstrap_f1s_calltaker = []\n",
    "for i in tqdm(range(n_bootstrap), desc=\"Bootstrap iterations\"):\n",
    "    precision_model_i = []\n",
    "    precision_calltaker_i = []\n",
    "    recall_model_i = []\n",
    "    recall_calltaker_i = []\n",
    "    f1s_model_i = []\n",
    "    f1s_calltaker_i = []\n",
    "    for low, high in zip(bin_edges[:-1], bin_edges[1:]):\n",
    "        cond = (model_probs_resampled[i] >= low) & (model_probs_resampled[i] < high)\n",
    "        \n",
    "        metrics_model = sklearn.metrics.precision_recall_fscore_support(targets_resampled[i][cond], model_preds_resampled[i][cond], zero_division=np.nan, average=\"binary\", pos_label=1)\n",
    "        metrics_calltaker = sklearn.metrics.precision_recall_fscore_support(targets_resampled[i][cond], human_preds_resampled[i][cond], zero_division=np.nan, average=\"binary\", pos_label=1)\n",
    "        \n",
    "        precision_model_i.append(metrics_model[0])\n",
    "        precision_calltaker_i.append(metrics_calltaker[0])\n",
    "        \n",
    "        recall_model_i.append(metrics_model[1])\n",
    "        recall_calltaker_i.append(metrics_calltaker[1])\n",
    "        \n",
    "        f1s_model_i.append(metrics_model[2])\n",
    "        f1s_calltaker_i.append(metrics_calltaker[2])\n",
    "\n",
    "    bootstrap_precision_model.append(precision_model_i)\n",
    "    bootstrap_precision_calltaker.append(precision_calltaker_i)\n",
    "\n",
    "    bootstrap_recall_model.append(recall_model_i)\n",
    "    bootstrap_recall_calltaker.append(recall_calltaker_i)\n",
    "\n",
    "    bootstrap_f1s_model.append(f1s_model_i)\n",
    "    bootstrap_f1s_calltaker.append(f1s_calltaker_i)\n",
    "\n",
    "bootstrap_precision_model = np.array(bootstrap_precision_model)\n",
    "bootstrap_precision_calltaker = np.array(bootstrap_precision_calltaker)\n",
    "bootstrap_recall_model = np.array(bootstrap_recall_model)\n",
    "bootstrap_recall_calltaker = np.array(bootstrap_recall_calltaker)\n",
    "bootstrap_f1s_model = np.array(bootstrap_f1s_model)\n",
    "bootstrap_f1s_calltaker = np.array(bootstrap_f1s_calltaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_calltaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_model_yerr = get_bootstrap_confidence_intervals_for_scalar(precision_model, bootstrap_precision_model, alpha=0.05)\n",
    "precision_calltaker_yerr = get_bootstrap_confidence_intervals_for_scalar(precision_calltaker, bootstrap_precision_calltaker, alpha=0.05)\n",
    "\n",
    "recall_model_yerr = get_bootstrap_confidence_intervals_for_scalar(recall_model, bootstrap_recall_model, alpha=0.05)\n",
    "recall_calltaker_yerr = get_bootstrap_confidence_intervals_for_scalar(recall_calltaker, bootstrap_recall_calltaker, alpha=0.05)\n",
    "\n",
    "f1s_model_yerr = get_bootstrap_confidence_intervals_for_scalar(f1s_model, bootstrap_f1s_model, alpha=0.05)\n",
    "f1s_calltaker_yerr = get_bootstrap_confidence_intervals_for_scalar(f1s_calltaker, bootstrap_f1s_calltaker, alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=(6.4, 4.8))\n",
    "ax2 = fig2.gca()\n",
    "\n",
    "ax2.errorbar(\n",
    "    x=bin_edges[:-1],\n",
    "    y=f1s_model,\n",
    "    yerr=f1s_model_yerr,\n",
    "    marker=\"o\",\n",
    "    markersize=3,\n",
    "    capsize=2,\n",
    "    label=\"Calibrated ensemble (isotonic)\"\n",
    ")\n",
    "\n",
    "ax2.errorbar(\n",
    "    x=bin_edges[:-1],\n",
    "    y=f1s_calltaker,\n",
    "    yerr=f1s_calltaker_yerr,\n",
    "    marker=\"o\",\n",
    "    markersize=3,\n",
    "    capsize=2,\n",
    "    label=\"Call-taker\"\n",
    ")\n",
    "\n",
    "# ax2.bar(bin_edges[:-1], f1s_model, width=bin_widths, align=\"edge\", alpha=0.5, label=\"Calibrated ensemble (isotonic)\")\n",
    "# ax2.bar(bin_edges[:-1], f1s_calltaker, width=bin_widths, align=\"edge\", alpha=0.5, label=\"Call-taker\")\n",
    "\n",
    "ax2.set_ylabel(\"F1-score\")\n",
    "\n",
    "ax2.set_xlabel(\"Predicted probability\")\n",
    "ax2.legend(loc=\"upper left\")\n",
    "fig2.savefig(\"f1_score_vs_predicted_probability_ensemble_calltaker_with_cis.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=(6.4, 4.8))\n",
    "ax2 = fig2.gca()\n",
    "\n",
    "ax2.errorbar(\n",
    "    x=bin_edges[:-1],\n",
    "    y=precision_model,\n",
    "    yerr=precision_model_yerr,\n",
    "    marker=\"o\",\n",
    "    markersize=3,\n",
    "    capsize=2,\n",
    "    label=\"Calibrated ensemble (isotonic)\"\n",
    ")\n",
    "\n",
    "ax2.errorbar(\n",
    "    x=bin_edges[:-1],\n",
    "    y=precision_calltaker,\n",
    "    yerr=precision_calltaker_yerr,\n",
    "    marker=\"o\",\n",
    "    markersize=3,\n",
    "    capsize=2,\n",
    "    label=\"Call-taker\"\n",
    ")\n",
    "\n",
    "# ax2.bar(bin_edges[:-1], precision_model, width=bin_widths, align=\"edge\", alpha=0.5, label=\"Calibrated ensemble (isotonic)\")\n",
    "# ax2.bar(bin_edges[:-1], precision_calltaker, width=bin_widths, align=\"edge\", alpha=0.5, label=\"Call-taker\")\n",
    "\n",
    "ax2.set_ylabel(\"Precision\")\n",
    "ax2.set_xlabel(\"Predicted probability\")\n",
    "ax2.legend(loc=\"upper left\")\n",
    "fig2.savefig(\"precision_vs_predicted_probability_ensemble_calltaker_with_cis.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=(6.4, 4.8))\n",
    "ax2 = fig2.gca()\n",
    "\n",
    "ax2.errorbar(\n",
    "    x=bin_edges[:-1],\n",
    "    y=recall_model,\n",
    "    yerr=recall_model_yerr,\n",
    "    marker=\"o\",\n",
    "    markersize=3,\n",
    "    capsize=2,\n",
    "    label=\"Calibrated ensemble (isotonic)\"\n",
    ")\n",
    "\n",
    "ax2.errorbar(\n",
    "    x=bin_edges[:-1],\n",
    "    y=recall_calltaker,\n",
    "    yerr=recall_calltaker_yerr,\n",
    "    marker=\"o\",\n",
    "    markersize=3,\n",
    "    capsize=2,\n",
    "    label=\"Call-taker\"\n",
    ")\n",
    "\n",
    "# ax2.bar(bin_edges[:-1], recall_model, width=bin_widths, align=\"edge\", alpha=0.5, label=\"Calibrated ensemble (isotonic)\")\n",
    "# ax2.bar(bin_edges[:-1], recall_calltaker, width=bin_widths, align=\"edge\", alpha=0.5, label=\"Call-taker\")\n",
    "\n",
    "ax2.set_ylabel(\"Recall\")\n",
    "ax2.set_xlabel(\"Predicted probability\")\n",
    "ax2.legend(loc=\"upper left\")\n",
    "fig2.savefig(\"recall_vs_predicted_probability_ensemble_calltaker_with_cis.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_main_positives = []\n",
    "num_main_negatives = []\n",
    "for low, high in zip(bin_edges[:-1], bin_edges[1:]):\n",
    "    cond = (model_probs_resampled[i] >= low) & (model_probs_resampled[i] < high)\n",
    "    \n",
    "    num_main_positives += [np.sum(targets[cond])]\n",
    "    num_main_negatives += [np.sum(1 - targets[cond])]\n",
    "    \n",
    "    metrics_model = sklearn.metrics.precision_recall_fscore_support(targets[cond], model_preds[cond], zero_division=np.nan, average=\"binary\", pos_label=1)\n",
    "\n",
    "num_main_positives = np.array(num_main_positives)\n",
    "num_main_negatives = np.array(num_main_negatives)\n",
    "\n",
    "num_positives = []\n",
    "num_negatives = []\n",
    "for i in tqdm(range(n_bootstrap), desc=\"Bootstrap iterations\"):\n",
    "    num_positives_i = []\n",
    "    num_negatives_i = []\n",
    "    for low, high in zip(bin_edges[:-1], bin_edges[1:]):\n",
    "        cond = (model_probs_resampled[i] >= low) & (model_probs_resampled[i] < high)\n",
    "        \n",
    "        num_positives_i += [np.sum(targets_resampled[i][cond])]\n",
    "        num_negatives_i += [np.sum(1 - targets_resampled[i][cond])]\n",
    "        \n",
    "        metrics_model = sklearn.metrics.precision_recall_fscore_support(targets_resampled[i][cond], model_preds_resampled[i][cond], zero_division=np.nan, average=\"binary\", pos_label=1)\n",
    "\n",
    "    num_positives.append(num_positives_i)\n",
    "    num_negatives.append(num_negatives_i)\n",
    "    \n",
    "num_positives = np.array(num_positives)\n",
    "num_negatives = np.array(num_negatives)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_err = get_bootstrap_confidence_intervals_for_scalar(num_main_positives, num_positives, alpha=0.05)\n",
    "neg_err = get_bootstrap_confidence_intervals_for_scalar(num_main_negatives, num_negatives, alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_main_positives, num_main_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Brier scores with CIs\n",
    "brier_scores = []\n",
    "for i in tqdm(range(n_bootstrap), desc=\"Bootstrap iterations\"):\n",
    "    brier_score = sklearn.metrics.brier_score_loss(targets_resampled[i], model_probs_resampled[i])\n",
    "    brier_scores.append(brier_score)\n",
    "brier_scores = np.array(brier_scores)\n",
    "\n",
    "brier_score = sklearn.metrics.brier_score_loss(targets, model_probs)\n",
    "\n",
    "brier_score_yerr = get_bootstrap_confidence_intervals_for_scalar(brier_score, brier_scores, alpha=0.05)\n",
    "\n",
    "# Compute Brier skill scores with CIs\n",
    "brier_skill_scores = []\n",
    "for i in tqdm(range(n_bootstrap), desc=\"Bootstrap iterations\"):\n",
    "    mean = np.array([targets_resampled[i].mean()] * len(targets_resampled[i]))\n",
    "    brier_skill_score = 1 - sklearn.metrics.brier_score_loss(targets_resampled[i], model_probs_resampled[i]) / sklearn.metrics.brier_score_loss(targets_resampled[i], mean)\n",
    "    brier_skill_scores.append(brier_skill_score)\n",
    "brier_skill_scores = np.array(brier_skill_scores)\n",
    "\n",
    "mean = np.array([targets.mean()] * len(targets))\n",
    "brier_skill_score = 1 - sklearn.metrics.brier_score_loss(targets, model_probs) / sklearn.metrics.brier_score_loss(targets, mean)\n",
    "\n",
    "brier_skill_score_yerr = get_bootstrap_confidence_intervals_for_scalar(brier_skill_score, brier_skill_scores, alpha=0.05)\n",
    "\n",
    "brier_score_yerr[0] = - brier_score_yerr[0]\n",
    "brier_skill_score_yerr[0] = - brier_skill_score_yerr[0]\n",
    "print(\"Brier score: \", brier_score, brier_score_yerr, brier_score_yerr + brier_score)\n",
    "print(\"Brier skill score: \", brier_skill_score, brier_skill_score_yerr, brier_skill_score_yerr + brier_skill_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ensembles_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"Stop here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble of ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ensembles_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ensembles_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ensembles_test_probs = [all_ensembles_test[f\"ensemble {i} probs\"] for i in range(1, 12)]\n",
    "labels = [f\"Ensemble {i}\" for i in range(1, 12)]\n",
    "\n",
    "plot_calibration_curve(\n",
    "    targets=median_ensemble_test[\"y\"],\n",
    "    model_probs=all_ensembles_test_probs,\n",
    "    labels=labels,\n",
    "    n_bins=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ensembles_test_probs = np.stack([all_ensembles_test[f\"ensemble {i} probs\"] for i in range(1, 12)])\n",
    "all_ensembles_test_preds = np.stack([all_ensembles_test[f\"ensemble {i} preds\"] for i in range(1, 12)])\n",
    "all_ensembles_val_probs = np.stack([all_ensembles_val[f\"ensemble {i} probs\"] for i in range(1, 12)])\n",
    "all_ensembles_val_preds = np.stack([all_ensembles_val[f\"ensemble {i} preds\"] for i in range(1, 12)])\n",
    "all_ensembles_test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_ensemble_test = median_ensemble_test[\"ensemble_probs\"]\n",
    "# majority_vote_test = np.mean(all_ensembles_test_preds, axis=0) > 0.5\n",
    "super_ensemble_probs_test = scipy.stats.hmean(all_ensembles_test_probs, axis=0)\n",
    "mean_ensemble_probs_test = np.mean(all_ensembles_test_probs, axis=0)\n",
    "\n",
    "med_ensemble_val = median_ensemble_val[\"ensemble_probs\"]\n",
    "# majority_vote_val = np.mean(all_ensembles_test_preds, axis=0) > 0.5\n",
    "super_ensemble_probs_val = scipy.stats.hmean(all_ensembles_val_probs, axis=0)\n",
    "mean_ensemble_probs_val = np.mean(all_ensembles_val_probs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calibration_curve(\n",
    "    targets=median_ensemble_test[\"y\"],\n",
    "    model_probs=[med_ensemble_test, super_ensemble_probs_test, mean_ensemble_probs_test],\n",
    "    labels=[\"Median ensemble\", \"Harmonic mean of all ensembles\", \"Mean of all ensembles\"],\n",
    "    n_bins=20,\n",
    ")\n",
    "plot_histogram(arrays=[med_ensemble_test, super_ensemble_probs_test, mean_ensemble_probs_test], labels=[\"Majority vote\", \"Super ensemble\", \"Mean ensemble\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Platt scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(penalty=\"none\", fit_intercept=True)\n",
    "logistic.fit(median_ensemble_val[\"ensemble_probs\"].to_numpy()[:, np.newaxis], median_ensemble_val[\"y\"].to_numpy())\n",
    "ensemble_probs_logistic = logistic.predict_proba(median_ensemble_test[\"ensemble_probs\"].to_numpy()[:, np.newaxis])[:, 1]\n",
    "ensemble_probs_logistic_val = logistic.predict_proba(median_ensemble_val[\"ensemble_probs\"].to_numpy()[:, np.newaxis])[:, 1]\n",
    "\n",
    "\n",
    "logistic = LogisticRegression(penalty=\"none\", fit_intercept=True)\n",
    "logistic.fit(super_ensemble_probs_val[:, np.newaxis], median_ensemble_val[\"y\"].to_numpy())\n",
    "ensemble_probs_logistic = logistic.predict_proba(super_ensemble_probs_test[:, np.newaxis])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic.coef_, logistic.intercept_, logistic.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_probs_logistic.min(), ensemble_probs_logistic.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calibration_curve(\n",
    "    targets=median_ensemble_test[\"y\"],\n",
    "    model_probs=[ensemble_probs_logistic],\n",
    "    labels=[\"Ensemble\"],\n",
    "    n_bins=20,\n",
    ")\n",
    "plot_histogram(arrays=[ensemble_probs_logistic], labels=[\"Ensemble\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_old = median_ensemble_test[\"age\"] >= 65\n",
    "plot_calibration_curve(\n",
    "    targets=[median_ensemble_test[\"y\"][is_old], median_ensemble_test[\"y\"][~is_old]],\n",
    "    model_probs=[ensemble_probs_logistic[is_old], ensemble_probs_logistic[~is_old]],\n",
    "    labels=[\"65+\", \"18-65\"],\n",
    "    n_bins=20,\n",
    ")\n",
    "plot_histogram(\n",
    "    arrays=[ensemble_probs_logistic[is_old], ensemble_probs_logistic[~is_old]],\n",
    "    labels=[\"65+\", \"18-65\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isotonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isotonic = IsotonicRegression(y_min=0, y_max=1, increasing=True, out_of_bounds=\"clip\")\n",
    "isotonic.fit(super_ensemble_probs_val, median_ensemble_val[\"y\"])\n",
    "ensemble_probs_isotonic = isotonic.transform(super_ensemble_probs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(arrays=[ensemble_probs_isotonic], labels=[\"Ensemble validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6.4, 4.8))\n",
    "ax.plot([0, 1], [0, 1], \"k:\", label=\"Perfect calibration\")\n",
    "ax.plot(isotonic.X_thresholds_, isotonic.y_thresholds_, \"-\", marker=\"o\", markersize=3, label=\"Isotonic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calibration_curve(\n",
    "    targets=median_ensemble_test[\"y\"],\n",
    "    model_probs=[ensemble_probs_isotonic],\n",
    "    labels=[\"Ensemble\"],\n",
    "    n_bins=20,\n",
    ")\n",
    "plot_histogram(arrays=[ensemble_probs_isotonic], labels=[\"Ensemble\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
